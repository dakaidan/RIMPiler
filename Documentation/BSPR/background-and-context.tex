\section*{Background and Context}

\subsection*{Reversible Computing}\label{subsec:rev-comp}
Reversible computing is a model of computing where all operations are reversible, and therefore, we can always recover the previous state of the system.
This has a number of applications, such as debugging, quantum computing, and overcoming the Landauer limit\cite{LandauerLimit, debug, richardpFeynmanLecturesComputation2018}.

The Landauer limit is a theoretical limit on the amount of energy required to perform a computation, and is proportional to the number of bits erased during the computation.
Overcoming this limit would allow for much more energy efficient computers, and while we are still far from achieving this, reversible computing is a necessary step towards it.

Quantum computing is a model of computing which uses quantum mechanical phenomena such as superposition and entanglement to perform computations, allowing for much more efficient algorithms for certain problems such as Shor's algorithm for factoring large numbers.

The ability to perform computations in reverse is also useful for debugging, as it allows us to step backwards through the execution of a program, and see how the state of the system changes.
this allows us to easily navigate the control flow of a program, and see how the state of the system changes with various data changes.

\subsection*{Programming Languages}\label{subsec:pl}
Programming languages are an abstraction over some model of computation, allowing developers to write programs in a more human-readable, and human-reasonable way.
A programming language is often comprised of both a specification, formally describing the syntax and semantics of the language, and a compiler or interpreter, which allows us to work with the language without having to perform manual translations to a lower level language.
Additionally, a programming language may allow for abstractions over the underlying model of computation, or specific architecture, allowing the same program to target different systems which may work in drastically different ways.

In the case of reversible computing and RIMP, the semantics of the language allow us to embed reversibility in a syntax which otherwise resembles a standard imperative programming language, allowing the developer to program in a way which is familiar to them, while still being able to take advantage of the benefits of reversible computing.

\subsection*{Lexers}\label{subsec:lexers}
Syntax is the set of rules which define the structure of a language, namely, what set of strings are valid strings, without necessarily defining the meaning of those strings.
A lexer is a program which takes a stream of characters as input, and outputs a stream of tokens based on some syntax.
This is useful for compilers and interpreters, as it allows us to not only break down the problem into smaller steps, but it can also act as a filter, removing any unwanted parts of the input, such as whitespace and comments, as well as catching any potential errors such as a string sequence which cannot correspond to any valid token.

Compiler designers often aim to produce POSIX lexers, as they allow us to disambiguate between tokens in a way that is easy to reason about.

There are many ways to implement a lexer, including finite state machines, and regular expressions.
In the case of regular expressions, we can further explore methods of implementing them, such as using the standard NFA construction such as through Thompson's construction\cite{NFAConstruction}, using a DFA construction such as the powerset construction, or by using derivatives\cite{Derivatives}.

\subsection*{Regular Expressions}\label{subsec:regex}
Regular expressions are a way of describing a set of strings, and are often used in lexers to describe the syntax of a language.
One way of implementing regular expressions is through derivatives, where we can take the derivative of a regular expression with respect to a character, and use this to determine whether a string is in the language described by the regular expression.
This can be extended to allow for POSIX lexing\cite{LexingDerivatives}.

\subsection*{Parsers}\label{subsec:parsers}
Parsers take a stream of tokens as input, and output a parse tree, which represents the structure of the program in an unambiguous way.
This tree then encodes the semantics of the program, and we can then perform further analysis on the tree, or perform various transformations on it.
There are many ways to implement a parser, some methods being top down, such as recursive descent, and bottom up, such as LR parsing\cite{KnuthLRParsing}.
Here we will use a mix of a custom top-down parser to handle statements and control flow, and Pratt parsing to handle expressions\cite{PrattParsing}.

Pratt parsing is a method of parsing expressions, where we assign a precedence to each token, and then use this to determine how to parse the expression.
It is a form of top-down operator precedence parsing, and is often used in conjunction with recursive descent parsing.

\subsection*{Single Static Assignment}\label{subsec:ssa}
Single static assignment is a form of intermediate representation, where each variable is assigned exactly once, and each assignment is given a unique name.
This allows for many optimisations, such as constant propagation, and dead code elimination to easily be performed on the program\cite{SSA, RSSA}.

It is also useful for portability, as LLVM IR is in SSA form, and so we can easily target LLVM, and therefore many architectures, by compiling to LLVM IR.

